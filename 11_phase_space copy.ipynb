{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/debian/anaconda3/envs/capedenv/lib/python3.10/site-packages/kornia/feature/lightglue.py:44: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n",
      "2024-12-13 21:13:11.817975: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-13 21:13:12.091960: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-13 21:13:13.491112: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/debian/anaconda3/envs/capedenv/lib/:/home/debian/anaconda3/envs/capedenv/lib/python3.10/site-packages/nvidia/cudnn/lib:\n",
      "2024-12-13 21:13:13.491262: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/debian/anaconda3/envs/capedenv/lib/:/home/debian/anaconda3/envs/capedenv/lib/python3.10/site-packages/nvidia/cudnn/lib:\n",
      "2024-12-13 21:13:13.491272: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from tqdm import tqdm\n",
    "from napatrackmater.Trackvector import (\n",
    "    BROWNIAN_FEATURES\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data from /home/debian/jz/Mari_Data_Oneat/Mari_Sixth_Dataset_Analysis/nuclei_membrane_tracking/dataframes/goblet_basal_dataframe_normalized_nuclei_predicted_morpho_feature_attention_shallowest_litest.csv\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'Sixth'\n",
    "home_folder = '/home/debian/jz/'\n",
    "channel = 'nuclei_'\n",
    "tracking_directory = f'{home_folder}Mari_Data_Oneat/Mari_{dataset_name}_Dataset_Analysis/nuclei_membrane_tracking/'\n",
    "data_frames_dir = os.path.join(tracking_directory, f'dataframes/')\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "normalized_dataframe = os.path.join(data_frames_dir , f'goblet_basal_dataframe_normalized_{channel}predicted_morpho_feature_attention_shallowest_litest.csv')\n",
    "print(f'reading data from {normalized_dataframe}')\n",
    "tracks_dataframe = pd.read_csv(normalized_dataframe)\n",
    "save_dir = os.path.join(tracking_directory, f'{channel}phasespaces')\n",
    "Path(save_dir).mkdir(exist_ok=True)\n",
    "deltat = 10\n",
    "class_map_gbr = {\n",
    "        0: \"Basal\",\n",
    "        1: \"Radial\",\n",
    "        2: \"Goblet\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trackmate_ids = [trackid for trackid in tracks_dataframe['TrackMate Track ID'].unique()]\n",
    "result_dict = {cell_type: {} for cell_type in class_map_gbr.values()}\n",
    "unique_time_points = tracks_dataframe['t'].unique()\n",
    "\n",
    "for i, time_point in enumerate(unique_time_points):\n",
    "    time_data = tracks_dataframe[tracks_dataframe['t'] == time_point]\n",
    "    \n",
    "    if i + 1 < len(unique_time_points):\n",
    "        next_time_point = unique_time_points[i + 1]\n",
    "        next_time_data = tracks_dataframe[tracks_dataframe['t'] == next_time_point]\n",
    "\n",
    "        for cell_type in class_map_gbr.values():\n",
    "            cell_type_data = time_data[time_data['Cell_Type'] == cell_type]\n",
    "            \n",
    "\n",
    "            if not cell_type_data.empty:\n",
    "                if time_point not in result_dict[cell_type]:\n",
    "                    result_dict[cell_type][time_point] = {}\n",
    "                for trackmate_id in cell_type_data['TrackMate Track ID'].unique():\n",
    "                    current_trackmate_id_data = cell_type_data[cell_type_data['TrackMate Track ID'] == trackmate_id]\n",
    "                    for track_id in current_trackmate_id_data['Track ID'].unique():\n",
    "                        track_features = current_trackmate_id_data[current_trackmate_id_data['Track ID'] == track_id][BROWNIAN_FEATURES].to_numpy()\n",
    "                        \n",
    "                        if not next_time_data.empty:\n",
    "                            next_cell_type_data = next_time_data[next_time_data['TrackMate Track ID'] == trackmate_id]\n",
    "                            next_track_features = next_cell_type_data[next_cell_type_data['Track ID'] == track_id][BROWNIAN_FEATURES].to_numpy()\n",
    "                            if next_track_features.shape[0] > 0 :\n",
    "                            \n",
    "                                derivative_features = next_track_features[0,:] - track_features\n",
    "                            \n",
    "\n",
    "                                for feature_name in BROWNIAN_FEATURES:\n",
    "                                    pair_key = f\"{feature_name}\"\n",
    "                                    if derivative_features.shape[0] > 0:\n",
    "                                        \n",
    "                                        pairwise_values = np.stack(\n",
    "                                            [track_features[:, BROWNIAN_FEATURES.index(feature_name)],\n",
    "                                            derivative_features[:, BROWNIAN_FEATURES.index(feature_name)]],\n",
    "                                            axis=1\n",
    "                                        )\n",
    "\n",
    "                                        if pair_key not in result_dict[cell_type][time_point]:\n",
    "                                            result_dict[cell_type][time_point][pair_key] = []\n",
    "\n",
    "                                        result_dict[cell_type][time_point][pair_key].append({\n",
    "                                            'Track ID': int(track_id),  \n",
    "                                            'Pairwise Values': pairwise_values\n",
    "                                        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def build_dataframe(result_dict):\n",
    "    \"\"\"Converts result_dict to a pandas DataFrame for plotting, including Track ID.\"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for cell_type, time_data in result_dict.items():\n",
    "        for time_point, feature_dict in time_data.items():\n",
    "            for feature_name, track_data in feature_dict.items():\n",
    "                for track_entry in track_data:\n",
    "                    track_id = track_entry['Track ID']\n",
    "                    pairwise_array = track_entry['Pairwise Values']\n",
    "\n",
    "                    for feature_value, derivative_value in pairwise_array:\n",
    "                        rows.append({\n",
    "                            'Cell Type': cell_type,\n",
    "                            'Time Point': time_point,\n",
    "                            'Feature phase space': feature_name,\n",
    "                            'Track ID': track_id, \n",
    "                            'Feature Value': feature_value,\n",
    "                            'Derivative Value': derivative_value\n",
    "                        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_phasespace(df, title='phasespace',  dataset_name='dataset'):\n",
    "    \"\"\"Plots the phase space using seaborn's kdeplot for all time points in one plot per feature, with a color bar.\"\"\"\n",
    "    \n",
    "    cmap = plt.cm.viridis\n",
    "    norm = matplotlib.colors.Normalize(vmin=df['Time Point'].min(), vmax=df['Time Point'].max())\n",
    "\n",
    "    for cell_type in df['Cell Type'].unique():\n",
    "        cell_type_df = df[df['Cell Type'] == cell_type]\n",
    "        \n",
    "        for feature_name in cell_type_df['Feature phase space'].unique():\n",
    "            phasespace_df = cell_type_df[cell_type_df['Feature phase space'] == feature_name]\n",
    "            print(f\"Plotting for {cell_type} and feature phase space {feature_name}\")\n",
    "            \n",
    "            fig, ax = plt.subplots(figsize=(8, 10))\n",
    "\n",
    "            for time_point in sorted(phasespace_df['Time Point'].unique()):\n",
    "                time_df = phasespace_df[phasespace_df['Time Point'] == time_point]\n",
    "\n",
    "                if len(time_df) < 2 or time_df['Feature Value'].nunique() < 2:\n",
    "                    print(f\"Skipping KDE for time {time_point} due to insufficient data.\")\n",
    "                    continue \n",
    "\n",
    "                color = cmap(norm(time_point))\n",
    "\n",
    "                sns.kdeplot(\n",
    "                    data=time_df,\n",
    "                    x='Feature Value',\n",
    "                    y='Derivative Value',\n",
    "                    label=f\"Time {time_point}\",\n",
    "                    alpha=0.5,\n",
    "                    ax=ax,\n",
    "                    color=color,\n",
    "                    warn_singular=False\n",
    "                )\n",
    "\n",
    "            ax.set_xlabel(f'{feature_name}', fontsize=14)\n",
    "            ax.set_ylabel(f'{feature_name}_derivative', fontsize=14)\n",
    "\n",
    "            sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "            sm.set_array([]) \n",
    "            cbar = fig.colorbar(sm, ax=ax, orientation='vertical')\n",
    "            cbar.set_label('Time Point', fontsize=14)\n",
    "\n",
    "            ax.set_title(f\"{title} - {cell_type} ({feature_name})\", fontsize=16)\n",
    "            ax.legend(title=\"Time Points\", loc=\"upper right\", fontsize=10)\n",
    "\n",
    "          \n",
    "\n",
    "            plot_filename = os.path.join(save_dir, f\"{title}_{cell_type}_{feature_name}_{dataset_name}_phasespace.png\")\n",
    "            plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "\n",
    "          \n",
    "\n",
    "\n",
    "def test_ergodicity(\n",
    "    df, \n",
    "    time_delta=50, \n",
    "):\n",
    "    \"\"\"\n",
    "    Tests ergodicity by comparing the average of time averages (tracks) with \n",
    "    the average of ensemble averages (time points) over specified time intervals.\n",
    "    Saves comparison plots for each feature, iterating over all cell types.\n",
    "    \"\"\"\n",
    "    \n",
    "    os.makedirs(save_dir, exist_ok=True)  # Ensure output directory exists\n",
    "    for cell_type in df['Cell Type'].unique():\n",
    "        # Iterate over all unique features in the dataframe\n",
    "        for feature_name in df['Feature phase space'].unique():\n",
    "            ergodicity_results = []\n",
    "            #failed_intervals_count = 0\n",
    "\n",
    "        \n",
    "            cell_type_df = df[df['Cell Type'] == cell_type]\n",
    "            total_time_points = len(cell_type_df['Time Point'].unique())\n",
    "            time_points = sorted(cell_type_df['Time Point'].unique())\n",
    "\n",
    "            for start_time in tqdm(range(0, total_time_points + 2 * time_delta, time_delta)):\n",
    "                if start_time + time_delta >= total_time_points:\n",
    "                    start_time = total_time_points - time_delta\n",
    "\n",
    "                end_time = min(start_time + time_delta, total_time_points)\n",
    "                time_interval_points = time_points[start_time:end_time]\n",
    "\n",
    "                interval_df = cell_type_df[cell_type_df['Time Point'].isin(time_interval_points)]\n",
    "                feature_df = interval_df[interval_df['Feature phase space'] == feature_name]\n",
    "\n",
    "                # Time averages for each track over the interval\n",
    "                track_time_averages = []\n",
    "                for track_id in feature_df['Track ID'].unique():\n",
    "                    track_df = feature_df[feature_df['Track ID'] == track_id]\n",
    "                    time_avg_feature = np.mean(track_df['Feature Value'].values)\n",
    "                    track_time_averages.append(time_avg_feature)\n",
    "\n",
    "                # Ensemble averages for each time point in the interval\n",
    "                time_point_ensemble_averages = []\n",
    "                for time_point in time_interval_points:\n",
    "                    time_df = feature_df[feature_df['Time Point'] == time_point]\n",
    "                    ensemble_avg_feature = np.mean(time_df['Feature Value'].values)\n",
    "                    time_point_ensemble_averages.append(ensemble_avg_feature)\n",
    "\n",
    "                # Compare average of time averages with average of ensemble averages\n",
    "                avg_time_avg_feature = np.mean(track_time_averages)\n",
    "                avg_ensemble_avg_feature = np.mean(time_point_ensemble_averages)\n",
    "                diff = abs(avg_time_avg_feature - avg_ensemble_avg_feature)\n",
    "\n",
    "                # Statistical threshold for difference\n",
    "                #tolerance = 0.05 * max(avg_time_avg_feature, avg_ensemble_avg_feature, 1e-6)  # 5% relative tolerance\n",
    "\n",
    "                #if diff > tolerance:\n",
    "                #    failed_intervals_count += 1\n",
    "                #    if failed_intervals_count >= max_failed_intervals:\n",
    "                #        print(f\"Too many failed intervals for {feature_name} in {cell_type}. Ergodicity not reached.\")\n",
    "                #        continue\n",
    "\n",
    "                # Record successful ergodic intervals\n",
    "                ergodicity_results.append({\n",
    "                    'Cell Type': cell_type,\n",
    "                    'Feature': feature_name,\n",
    "                    'Interval': f\"{start_time}-{end_time}\",\n",
    "                    'Time Avg': avg_time_avg_feature,\n",
    "                    'Ensemble Avg': avg_ensemble_avg_feature,\n",
    "                    'Difference': diff,\n",
    "                })\n",
    "\n",
    "            # Save results and plot for each feature\n",
    "            if ergodicity_results:\n",
    "                ergodicity_df = pd.DataFrame(ergodicity_results)\n",
    "                sns.set(style=\"whitegrid\")\n",
    "                plt.figure(figsize=(10, 6))\n",
    "\n",
    "                # Plot each cell type's results\n",
    "                for cell_type in ergodicity_df['Cell Type'].unique():\n",
    "                    cell_type_data = ergodicity_df[ergodicity_df['Cell Type'] == cell_type]\n",
    "                    sns.lineplot(\n",
    "                        data=cell_type_data, \n",
    "                        x=\"Interval\", \n",
    "                        y=\"Time Avg\", \n",
    "                        label=f\"{cell_type} Time Avg\", \n",
    "                        marker=\"o\"\n",
    "                    )\n",
    "                    sns.lineplot(\n",
    "                        data=cell_type_data, \n",
    "                        x=\"Interval\", \n",
    "                        y=\"Ensemble Avg\", \n",
    "                        label=f\"{cell_type} Ensemble Avg\", \n",
    "                        marker=\"s\"\n",
    "                    )\n",
    "\n",
    "                \n",
    "\n",
    "                plt.title(f\"Ergodicity Test for {cell_type}_{feature_name}\")\n",
    "                plt.ylabel(\"Value\")\n",
    "                plt.xlabel(\"Time Interval\")\n",
    "                plt.legend()\n",
    "                plt.xticks(rotation=45)\n",
    "                plt.tight_layout()\n",
    "\n",
    "                # Save plot for each feature\n",
    "                plot_path = os.path.join(save_dir, f\"ergodicity_{cell_type}_{feature_name}.png\")\n",
    "                plt.savefig(plot_path)\n",
    "                plt.show()\n",
    "                plt.close()\n",
    "                print(f\"Saved plot for {feature_name} at {plot_path}\")\n",
    "            else:\n",
    "                print(f\"No ergodic intervals detected for feature {cell_type}_{feature_name}.\")\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dataframe = build_dataframe(result_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ergodicity(feature_dataframe, time_delta=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_phasespace(feature_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capedenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
