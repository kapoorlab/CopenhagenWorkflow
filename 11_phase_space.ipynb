{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/debian/anaconda3/envs/capedenv/lib/python3.10/site-packages/kornia/feature/lightglue.py:44: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n",
      "2024-12-08 20:38:12.658231: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-08 20:38:12.874443: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-08 20:38:13.778042: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/debian/anaconda3/envs/capedenv/lib/:/home/debian/anaconda3/envs/capedenv/lib/python3.10/site-packages/nvidia/cudnn/lib:\n",
      "2024-12-08 20:38:13.778228: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/debian/anaconda3/envs/capedenv/lib/:/home/debian/anaconda3/envs/capedenv/lib/python3.10/site-packages/nvidia/cudnn/lib:\n",
      "2024-12-08 20:38:13.778241: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations\n",
    "from napatrackmater.Trackvector import (\n",
    "    BROWNIAN_FEATURES\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data from /home/debian/jz/Mari_Data_Oneat/Mari_Sixth_Dataset_Analysis/nuclei_membrane_tracking/dataframes/goblet_basal_dataframe_normalized_nuclei_.csv\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'Sixth'\n",
    "home_folder = '/home/debian/jz/'\n",
    "channel = 'nuclei_'\n",
    "tracking_directory = f'{home_folder}Mari_Data_Oneat/Mari_{dataset_name}_Dataset_Analysis/nuclei_membrane_tracking/'\n",
    "data_frames_dir = os.path.join(tracking_directory, f'dataframes/')\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "normalized_dataframe = os.path.join(data_frames_dir , f'goblet_basal_dataframe_normalized_{channel}.csv')\n",
    "print(f'reading data from {normalized_dataframe}')\n",
    "tracks_dataframe = pd.read_csv(normalized_dataframe)\n",
    "save_dir = os.path.join(tracking_directory, f'{channel}phasespaces')\n",
    "Path(save_dir).mkdir(exist_ok=True)\n",
    "deltat = 10\n",
    "class_map_gbr = {\n",
    "        0: \"Basal\",\n",
    "        1: \"Radial\",\n",
    "        2: \"Goblet\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trackmate_ids = [trackid for trackid in tracks_dataframe['TrackMate Track ID'].unique()]\n",
    "result_dict = {cell_type: {} for cell_type in class_map_gbr.values()}\n",
    "unique_time_points = tracks_dataframe['t'].unique()\n",
    "\n",
    "for time_point in unique_time_points:\n",
    "    time_data = tracks_dataframe[tracks_dataframe['t'] == time_point]\n",
    "\n",
    "    for cell_type in class_map_gbr.values():\n",
    "        cell_type_data = time_data[time_data['Cell_Type'] == cell_type]\n",
    "        \n",
    "        if not cell_type_data.empty:\n",
    "            if time_point not in result_dict[cell_type]:\n",
    "                result_dict[cell_type][time_point] = {}\n",
    "\n",
    "            for track_id in cell_type_data['Track ID'].unique():\n",
    "                track_features = cell_type_data[cell_type_data['Track ID'] == track_id][BROWNIAN_FEATURES].to_numpy()\n",
    "\n",
    "                feature_pairs = list(combinations(BROWNIAN_FEATURES, 2))\n",
    "\n",
    "                for (feature_name1, feature_name2) in feature_pairs:\n",
    "                    pair_key = f\"{feature_name1}_vs_{feature_name2}\"\n",
    "\n",
    "                    pairwise_values = np.stack(\n",
    "                        [track_features[:, BROWNIAN_FEATURES.index(feature_name1)],\n",
    "                         track_features[:, BROWNIAN_FEATURES.index(feature_name2)]],\n",
    "                        axis=1\n",
    "                    )\n",
    "\n",
    "                    if pair_key not in result_dict[cell_type][time_point]:\n",
    "                        result_dict[cell_type][time_point][pair_key] = []\n",
    "\n",
    "                    result_dict[cell_type][time_point][pair_key].append({\n",
    "                        'Track ID': int(track_id),  \n",
    "                        'Pairwise Values': pairwise_values\n",
    "                    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataframe(result_dict):\n",
    "    \"\"\"Converts result_dict to a pandas DataFrame for plotting, including Track ID.\"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for cell_type, time_data in result_dict.items():\n",
    "        for time_point, feature_dict in time_data.items():\n",
    "            for feature_pair, track_data in feature_dict.items():\n",
    "                for track_entry in track_data:\n",
    "                    track_id = track_entry['Track ID']\n",
    "                    pairwise_array = track_entry['Pairwise Values']\n",
    "\n",
    "                    feature_name1, feature_name2 = feature_pair.split('_vs_')\n",
    "                    for feature1, feature2 in pairwise_array:\n",
    "                        rows.append({\n",
    "                            'Cell Type': cell_type,\n",
    "                            'Time Point': time_point,\n",
    "                            'Feature Pair': feature_pair,\n",
    "                            'Track ID': track_id, \n",
    "                            feature_name1: feature1,\n",
    "                            feature_name2: feature2,\n",
    "                        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_phasespace(df, title='phasespace'):\n",
    "    \"\"\"Plots the phase space using seaborn's kdeplot for all time points in one plot per feature pair, with a color bar.\"\"\"\n",
    "\n",
    "    cmap = plt.cm.viridis\n",
    "    norm = matplotlib.colors.Normalize(vmin=df['Time Point'].min(), vmax=df['Time Point'].max())\n",
    "    \n",
    "    all_feature_pairs = list(df['Feature Pair'].unique())\n",
    "\n",
    "    for cell_type in df['Cell Type'].unique():\n",
    "        cell_type_df = df[df['Cell Type'] == cell_type]\n",
    "\n",
    "        plt.figure(figsize=(15, 5 * len(all_feature_pairs)))\n",
    "\n",
    "        plot_idx = 0  \n",
    "        \n",
    "        for feature_pair in all_feature_pairs:\n",
    "            pair_df = cell_type_df[cell_type_df['Feature Pair'] == feature_pair]\n",
    "            print(f\"Plotting for {cell_type} and feature pair {feature_pair}\")\n",
    "\n",
    "            actual_feature_name1, actual_feature_name2 = feature_pair.split('_vs_')\n",
    "\n",
    "            plt.figure(figsize=(8, 6))  \n",
    "            \n",
    "            for time_point in sorted(pair_df['Time Point'].unique()):\n",
    "                time_df = pair_df[pair_df['Time Point'] == time_point]\n",
    "                color = cmap(norm(time_point))\n",
    "\n",
    "                sns.kdeplot(\n",
    "                    data=time_df,\n",
    "                    x=actual_feature_name1,\n",
    "                    y=actual_feature_name2,\n",
    "                    label=f\"Time {time_point}\",\n",
    "                    alpha=0.5,\n",
    "                    color=color\n",
    "                )\n",
    "\n",
    "            plt.xlabel(f\"{actual_feature_name1}\", fontsize=12)\n",
    "            plt.ylabel(f\"{actual_feature_name2}\", fontsize=12)\n",
    "            plt.title(f\"{cell_type}: {actual_feature_name1} vs {actual_feature_name2}\", fontsize=14)\n",
    "            plt.legend(title=\"Time Points\", loc=\"upper right\", fontsize=10)\n",
    "\n",
    "            sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "            sm.set_array([]) \n",
    "            cbar = plt.colorbar(sm)  \n",
    "            cbar.set_label('Time Point', fontsize=12)\n",
    "\n",
    "            plot_filename = os.path.join(save_dir, f\"{title}_{cell_type}_{actual_feature_name1}_{actual_feature_name2}_phasespace.png\")\n",
    "            plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            plt.close() \n",
    "\n",
    "            ax = plt.subplot(len(all_feature_pairs), 1, plot_idx + 1)  \n",
    "            \n",
    "            for time_point in sorted(pair_df['Time Point'].unique()):\n",
    "                time_df = pair_df[pair_df['Time Point'] == time_point]\n",
    "                color = cmap(norm(time_point))\n",
    "\n",
    "                sns.kdeplot(\n",
    "                    data=time_df,\n",
    "                    x=actual_feature_name1,\n",
    "                    y=actual_feature_name2,\n",
    "                    label=f\"Time {time_point}\",\n",
    "                    alpha=0.5,\n",
    "                    ax=ax,\n",
    "                    color=color\n",
    "                )\n",
    "\n",
    "            ax.set_xlabel(f\"{actual_feature_name1}\", fontsize=12)\n",
    "            ax.set_ylabel(f\"{actual_feature_name2}\", fontsize=12)\n",
    "            ax.set_title(f\"{cell_type}: {actual_feature_name1} vs {actual_feature_name2}\", fontsize=14)\n",
    "            ax.legend(title=\"Time Points\", loc=\"upper right\", fontsize=10)\n",
    "\n",
    "            sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "            sm.set_array([])  \n",
    "            cbar = plt.colorbar(sm, ax=ax)  \n",
    "            cbar.set_label('Time Point', fontsize=12)\n",
    "\n",
    "            plot_idx += 1  \n",
    "\n",
    "        combined_plot_filename = os.path.join(save_dir, f\"{title}_{cell_type}_combined_phasespace.png\")\n",
    "        plt.savefig(combined_plot_filename, dpi=300, bbox_inches='tight')\n",
    "        plt.show() \n",
    "          \n",
    "\n",
    "def test_ergodicity(df, feature1='Radius', feature2='Eccentricity_Comp_First', error_tolerance=0.5, time_delta=50, max_failed_tracks=10):\n",
    "    \n",
    "    ergodicity_times = []\n",
    "    max_diff1_global = -float('inf')\n",
    "    min_diff1_global = float('inf')\n",
    "    max_diff2_global = -float('inf')\n",
    "    min_diff2_global = float('inf')\n",
    "\n",
    "    for feature_pair in df['Feature Pair'].unique():\n",
    "        if feature1 not in feature_pair or feature2 not in feature_pair:\n",
    "            continue\n",
    "        \n",
    "        pair_df = df[df['Feature Pair'] == feature_pair]\n",
    "        actual_feature_name1, actual_feature_name2 = feature_pair.split('_vs_')\n",
    "\n",
    "        for cell_type in df['Cell Type'].unique():\n",
    "            \n",
    "            cell_type_df = pair_df[pair_df['Cell Type'] == cell_type]\n",
    "\n",
    "            total_time_points = len(cell_type_df['Time Point'].unique())\n",
    "            time_points = sorted(cell_type_df['Time Point'].unique())\n",
    "\n",
    "            for start_time in tqdm(range(0, total_time_points + 2 * time_delta, time_delta)):\n",
    "                if start_time + time_delta >= total_time_points:\n",
    "                    start_time = total_time_points - time_delta\n",
    "\n",
    "                end_time = min(start_time + time_delta, total_time_points)\n",
    "                time_interval_points = time_points[start_time:end_time]\n",
    "\n",
    "                time_averages = {}\n",
    "                for track_id in cell_type_df['Track ID'].unique():\n",
    "                    track_df = cell_type_df[cell_type_df['Track ID'] == track_id]\n",
    "                    time_averages[track_id] = (\n",
    "                        np.mean(track_df[actual_feature_name1].values/time_delta),\n",
    "                        np.mean(track_df[actual_feature_name2].values/time_delta)\n",
    "                    )\n",
    "\n",
    "                ensemble_averages = {}\n",
    "                for time_point in time_interval_points:\n",
    "                    time_df = cell_type_df[cell_type_df['Time Point'] == time_point]\n",
    "                    ensemble_averages[time_point] = (\n",
    "                        np.mean(time_df[actual_feature_name1].values),\n",
    "                        np.mean(time_df[actual_feature_name2].values)\n",
    "                    )\n",
    "\n",
    "                failed_tracks_count = 0\n",
    "                for track_id, (time_avg1, time_avg2) in time_averages.items():\n",
    "                    for time_point in time_interval_points:\n",
    "                        ensemble_avg1, ensemble_avg2 = ensemble_averages[time_point]\n",
    "                        diff1 = abs(time_avg1 - ensemble_avg1)\n",
    "                        diff2 = abs(time_avg2 - ensemble_avg2)\n",
    "\n",
    "                        # Track global max/min differences\n",
    "                        max_diff1_global = max(max_diff1_global, diff1)\n",
    "                        min_diff1_global = min(min_diff1_global, diff1)\n",
    "                        max_diff2_global = max(max_diff2_global, diff2)\n",
    "                        min_diff2_global = min(min_diff2_global, diff2)\n",
    "\n",
    "                        if diff1 > error_tolerance or diff2 > error_tolerance:\n",
    "                            failed_tracks_count += 1\n",
    "                            break\n",
    "                    if failed_tracks_count >= max_failed_tracks:\n",
    "                        break\n",
    "\n",
    "                if failed_tracks_count < max_failed_tracks:\n",
    "                    ergodicity_times.append({\n",
    "                        'Cell Type': cell_type,\n",
    "                        'Ergodic Time Interval': f\"{start_time}-{end_time}\"\n",
    "                    })\n",
    "                    \n",
    "        if ergodicity_times:\n",
    "            ergodicity_df = pd.DataFrame(ergodicity_times)\n",
    "            print(\"Ergodicity Times:\\n\", ergodicity_df)\n",
    "        else:\n",
    "            print(f\"Ergodicity was not reached within the specified intervals.\")\n",
    "\n",
    "    # Print global max/min differences\n",
    "    print(f\"Max difference for {feature1}: {max_diff1_global}\")\n",
    "    print(f\"Min difference for {feature1}: {min_diff1_global}\")\n",
    "    print(f\"Max difference for {feature2}: {max_diff2_global}\")\n",
    "    print(f\"Min difference for {feature2}: {min_diff2_global}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dataframe = build_dataframe(result_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:12<00:00,  1.21s/it]\n",
      "100%|██████████| 9/9 [00:00<00:00,  9.83it/s]\n",
      "100%|██████████| 10/10 [00:05<00:00,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ergodicity Times:\n",
      "   Cell Type Ergodic Time Interval\n",
      "0     Basal               150-200\n",
      "1     Basal               200-250\n",
      "2     Basal               250-300\n",
      "3    Radial               150-200\n",
      "4    Radial               200-250\n",
      "5    Goblet               200-250\n",
      "6    Goblet               250-300\n",
      "Max difference for Radius: 2.8462131258630907\n",
      "Min difference for Radius: 3.0440446427068557e-07\n",
      "Max difference for Eccentricity_Comp_First: 2.641090450209426\n",
      "Min difference for Eccentricity_Comp_First: 7.352665678146686e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_ergodicity(feature_dataframe, feature1='Radius', feature2='Eccentricity_Comp_First')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting for Basal and feature pair Radius_vs_Eccentricity_Comp_First\n"
     ]
    }
   ],
   "source": [
    "\n",
    "plot_phasespace(feature_dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capedenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
