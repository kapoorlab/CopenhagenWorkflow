{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from napatrackmater.Trackvector import (\n",
    "    BROWNIAN_FEATURES\n",
    ")\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'Fifth'\n",
    "home_folder = '/home/debian/jz/'\n",
    "channel = 'membrane_'\n",
    "tracking_directory = f'{home_folder}Mari_Data_Oneat/Mari_{dataset_name}_Dataset_Analysis/nuclei_membrane_tracking/'\n",
    "data_frames_dir = os.path.join(tracking_directory, f'dataframes/')\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tracklet_length = 25\n",
    "normalized_dataframe = os.path.join(data_frames_dir , f'goblet_basal_dataframe_normalized_{channel}.csv')\n",
    "print(f'reading data from {normalized_dataframe}')\n",
    "tracks_dataframe = pd.read_csv(normalized_dataframe)\n",
    "save_dir = os.path.join(tracking_directory, f'{channel}morphospaces')\n",
    "Path(save_dir).mkdir(exist_ok=True)\n",
    "n_components = 7\n",
    "deltat = 10\n",
    "poly_order = 3\n",
    "class_map_gbr = {\n",
    "        0: \"Basal\",\n",
    "        1: \"Radial\",\n",
    "        2: \"Goblet\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trackmate_ids = [trackid  for trackid in tracks_dataframe['TrackMate Track ID'].unique()]\n",
    "result_dict = {cell_type: {} for cell_type in class_map_gbr.values()}\n",
    "variance_summary = {cell_type: {} for cell_type in class_map_gbr.values()}\n",
    "unique_time_points = tracks_dataframe['t'].unique()\n",
    "\n",
    "for time_point in unique_time_points:\n",
    "    time_data = tracks_dataframe[tracks_dataframe['t'] == time_point]\n",
    "\n",
    "    for cell_type in class_map_gbr.values():\n",
    "        cell_type_data = time_data[time_data['Cell_Type'] == cell_type]\n",
    "\n",
    "        if not cell_type_data.empty:\n",
    "            \n",
    "            features_list = []\n",
    "            track_id_list = [] \n",
    "            for trackmate_id in cell_type_data['TrackMate Track ID'].unique():\n",
    "                current_trackmate_data = cell_type_data[cell_type_data['TrackMate Track ID'] == trackmate_id]\n",
    "                \n",
    "                for track_id in current_trackmate_data['Track ID'].unique():\n",
    "                    \n",
    "                    track_features = current_trackmate_data[current_trackmate_data['Track ID'] == track_id][BROWNIAN_FEATURES].to_numpy()\n",
    "                  \n",
    "                    features_list.append(track_features)\n",
    "                    track_id_list.extend([track_id] * track_features.shape[0]) \n",
    "            concatenated_features = np.vstack(features_list)\n",
    "            \n",
    "            if concatenated_features.shape[0] > n_components: \n",
    "                pca = PCA(n_components=n_components)\n",
    "                principal_components = pca.fit_transform(concatenated_features)\n",
    "                explained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "            \n",
    "                total_variance_explained = sum(explained_variance)\n",
    "                if time_point not in variance_summary[cell_type]:\n",
    "                    variance_summary[cell_type][time_point] = total_variance_explained\n",
    "\n",
    "                if time_point not in result_dict[cell_type]:\n",
    "                    result_dict[cell_type][time_point] = []\n",
    "\n",
    "            \n",
    "                result_dict[cell_type][time_point].append({\n",
    "                    'principal_components': principal_components,\n",
    "                    'track_ids': track_id_list  \n",
    "                })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell_type, time_data in variance_summary.items():\n",
    "    time_points = sorted(time_data.keys())\n",
    "    variances = [time_data[time_point] for time_point in time_points]\n",
    "    \n",
    "    plt.plot(time_points, variances, marker='o', label=f'{cell_type}')\n",
    "\n",
    "plt.title('Explained Variance Over Time for Each Cell Type', fontsize=16)\n",
    "plt.xlabel('Time Point', fontsize=14)\n",
    "plt.ylabel('Total Explained Variance', fontsize=14)\n",
    "plt.legend(title='Cell Type', fontsize=12, loc='upper right')\n",
    "plt.grid(alpha=0.5)\n",
    "plt.tight_layout()\n",
    "\n",
    "plot_filename = os.path.join(save_dir, f\"{dataset_name}_explained_variance_lineplot.png\")\n",
    "plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivative_dict = {cell_type: {} for cell_type in class_map_gbr.values()}\n",
    "derivative_square_dict = {cell_type: {} for cell_type in class_map_gbr.values()}\n",
    "\n",
    "norm_diff_dict = {cell_type: {} for cell_type in class_map_gbr.values()}\n",
    "for cell_type in class_map_gbr.values():\n",
    "\n",
    "    for time_idx, time_point in enumerate(unique_time_points[:-1]):  \n",
    "        if time_idx + deltat < max(unique_time_points):\n",
    "                next_time_point = unique_time_points[time_idx + deltat]\n",
    "\n",
    "                if time_point in result_dict[cell_type] and next_time_point in result_dict[cell_type]:\n",
    "                    curr_data = result_dict[cell_type][time_point][0]\n",
    "                    next_data = result_dict[cell_type][next_time_point][0]\n",
    "\n",
    "                    curr_features = curr_data['principal_components']  # (N, F)\n",
    "                    next_features = next_data['principal_components']  # (M, F)\n",
    "\n",
    "                    curr_track_ids = np.array(curr_data['track_ids'])  # (N,)\n",
    "                    next_track_ids = np.array(next_data['track_ids'])  # (M,)\n",
    "\n",
    "                    common_track_ids, curr_indices, next_indices = np.intersect1d(\n",
    "                        curr_track_ids, next_track_ids, return_indices=True\n",
    "                    )\n",
    "\n",
    "                    if len(common_track_ids) == 0:\n",
    "                        continue \n",
    "\n",
    "                    aligned_curr_features = curr_features[curr_indices]\n",
    "                    aligned_next_features = next_features[next_indices]\n",
    "\n",
    "                    # Compute the norm differences\n",
    "                    curr_norms = np.linalg.norm(aligned_curr_features, axis=1)  # Norms of current features\n",
    "                    next_norms = np.linalg.norm(aligned_next_features, axis=1)  # Norms of next features\n",
    "                    norm_differences = next_norms - curr_norms\n",
    "\n",
    "                    time_derivative = (aligned_next_features - aligned_curr_features) \n",
    "                    \n",
    "                    if time_point not in derivative_dict[cell_type]:\n",
    "                        derivative_dict[cell_type][time_point] = []\n",
    "                        derivative_square_dict[cell_type][time_point] = []\n",
    "                        norm_diff_dict[cell_type][time_point] = []\n",
    "\n",
    "                    derivative_dict[cell_type][time_point].append({'principal_components': time_derivative/ deltat, 'track_id_list': next_features })\n",
    "                    derivative_square_dict[cell_type][time_point].append({ 'principal_components': time_derivative * time_derivative * 0.5/ deltat, 'track_id_list': next_features  })\n",
    "                    norm_diff_dict[cell_type][time_point].append({ 'principal_components': norm_differences, 'track_id_list': next_features  })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_pcs_density_and_stats(result_dict, n_components=5, selected_pc=1, title='Density and Stats of PC1 Across Cell Types'):\n",
    "    if selected_pc < 1 or selected_pc > n_components:\n",
    "        print(f\"Invalid principal component number. Please choose a number between 1 and {n_components}.\")\n",
    "        return\n",
    "\n",
    "    cell_types = [cell_type for cell_type in class_map_gbr.values() if cell_type in result_dict]\n",
    "    n_cell_types = len(cell_types)\n",
    "\n",
    "    n_rows = int(np.ceil(n_cell_types))\n",
    "    fig, axes = plt.subplots(n_rows, 3, figsize=(18, 6 * n_rows), constrained_layout=True)\n",
    "\n",
    "    axes = axes.reshape(-1, 3)\n",
    "\n",
    "    for idx, cell_type in enumerate(cell_types):\n",
    "        ax_density = axes[idx, 0]\n",
    "\n",
    "        all_data = []\n",
    "        all_labels = []\n",
    "\n",
    "        for time_point in sorted(result_dict[cell_type].keys()):\n",
    "            data = result_dict[cell_type][time_point][0]\n",
    "            pcs = data['principal_components']  # (N, F)\n",
    "\n",
    "            pc_values = pcs[:, selected_pc - 1]\n",
    "\n",
    "            all_data.extend(pc_values)\n",
    "            all_labels.extend([f'Time {time_point}'] * len(pc_values))\n",
    "\n",
    "        df_density = pd.DataFrame({'PC Value': all_data, 'Time Point': all_labels})\n",
    "        sns.kdeplot(\n",
    "            data=df_density,\n",
    "            x='PC Value',\n",
    "            hue='Time Point',\n",
    "            ax=ax_density,\n",
    "            palette='tab20',\n",
    "            linewidth=1.5,\n",
    "            legend=False\n",
    "        )\n",
    "        ax_density.set_title(f' PC{selected_pc} for {cell_type}', fontsize=14)\n",
    "        ax_density.set_xlabel(f'PC{selected_pc} Value', fontsize=12)\n",
    "        ax_density.set_ylabel('Density', fontsize=12)\n",
    "\n",
    "        ax_stats = axes[idx, 1]\n",
    "        ax_mean = axes[idx, 2]\n",
    "\n",
    "        time_points = sorted(result_dict[cell_type].keys())\n",
    "        variances = []\n",
    "        means = [] \n",
    "        for time_point in time_points:\n",
    "            data = result_dict[cell_type][time_point][0]\n",
    "            pcs = data['principal_components']  # (N, F)\n",
    "            pc_values = pcs[:, selected_pc - 1]\n",
    "\n",
    "            variances.append(np.var(pc_values))\n",
    "            means.append(np.mean(pc_values))\n",
    "\n",
    "        #variance_poly_coeff = np.polyfit(time_points, variances, poly_order)\n",
    "        #mean_poly_coeff = np.polyfit(time_points, means, poly_order)\n",
    "        \n",
    "        #variances = np.polyval(variance_poly_coeff, time_points)\n",
    "        #means = np.polyval(mean_poly_coeff, time_points)    \n",
    "\n",
    "        df_variance = pd.DataFrame({'Time Point': time_points, 'Variance': variances, 'Mean': means})\n",
    "        sns.lineplot(data=df_variance, x='Time Point', y='Variance', marker='o', ax=ax_stats)\n",
    "        ax_stats.set_title(f'Variance of PC{selected_pc} for {cell_type}', fontsize=14)\n",
    "        ax_stats.set_xlabel('Time', fontsize=12)\n",
    "        ax_stats.set_ylabel(f'PC{selected_pc} Variance', fontsize=12)\n",
    "\n",
    "        sns.lineplot(data=df_variance, x='Time Point', y='Mean', marker='o', ax=ax_mean)\n",
    "        ax_mean.set_title(f'Mean of PC{selected_pc} for {cell_type}', fontsize=14)\n",
    "        ax_mean.set_xlabel('Time', fontsize=12)\n",
    "        ax_mean.set_ylabel(f'PC{selected_pc} Mean', fontsize=12)\n",
    "\n",
    "    for idx in range(n_cell_types, axes.shape[0]):\n",
    "        axes[idx, 0].axis('off')\n",
    "        axes[idx, 1].axis('off')\n",
    "        axes[idx, 2].axis('off')\n",
    "\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    plot_filename = os.path.join(save_dir, f\"{title.replace(' ', '_')}_PC{selected_pc}_{dataset_name}_density_stats.png\")\n",
    "    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_all_pcs_density_and_stats(result_dict,  title='Density and Stats of PC1 Across Cell Types'):\n",
    "   \n",
    "\n",
    "    cell_types = [cell_type for cell_type in class_map_gbr.values() if cell_type in result_dict]\n",
    "    n_cell_types = len(cell_types)\n",
    "\n",
    "    n_rows = int(np.ceil(n_cell_types))\n",
    "    fig, axes = plt.subplots(n_rows, 3, figsize=(18, 6 * n_rows), constrained_layout=True)\n",
    "\n",
    "    axes = axes.reshape(-1, 3)\n",
    "\n",
    "    for idx, cell_type in enumerate(cell_types):\n",
    "        ax_density = axes[idx, 0]\n",
    "\n",
    "        all_data = []\n",
    "        all_labels = []\n",
    "\n",
    "        for time_point in sorted(result_dict[cell_type].keys()):\n",
    "            data = result_dict[cell_type][time_point][0]\n",
    "            pcs = data['principal_components']  # (N, F)\n",
    "\n",
    "            pc_values = np.linalg.norm(pcs, axis=1)\n",
    "\n",
    "            all_data.extend(pc_values)\n",
    "            all_labels.extend([f'Time {time_point}'] * len(pc_values))\n",
    "\n",
    "        df_density = pd.DataFrame({'PC Value': all_data, 'Time Point': all_labels})\n",
    "        sns.kdeplot(\n",
    "            data=df_density,\n",
    "            x='PC Value',\n",
    "            hue='Time Point',\n",
    "            ax=ax_density,\n",
    "            palette='tab20',\n",
    "            linewidth=1.5,\n",
    "            legend=False\n",
    "        )\n",
    "        ax_density.set_title(f' all PC for {cell_type}', fontsize=14)\n",
    "        ax_density.set_xlabel(f'all PC Value', fontsize=12)\n",
    "        ax_density.set_ylabel('Density', fontsize=12)\n",
    "\n",
    "        ax_stats = axes[idx, 1]\n",
    "        ax_mean = axes[idx, 2]\n",
    "\n",
    "        time_points = sorted(result_dict[cell_type].keys())\n",
    "        variances = []\n",
    "        means = [] \n",
    "        for time_point in time_points:\n",
    "            data = result_dict[cell_type][time_point][0]\n",
    "            pcs = data['principal_components']  # (N, F)\n",
    "            pc_values = np.linalg.norm(pcs, axis=1)\n",
    "\n",
    "            variances.append(np.var(pc_values))\n",
    "            means.append(np.mean(pc_values))\n",
    "            \n",
    "        #variance_poly_coeff = np.polyfit(time_points, variances, poly_order)\n",
    "        #mean_poly_coeff = np.polyfit(time_points, means, poly_order)\n",
    "        \n",
    "        #variances = np.polyval(variance_poly_coeff, time_points)\n",
    "        #means = np.polyval(mean_poly_coeff, time_points)\n",
    "        df_variance = pd.DataFrame({'Time Point': time_points, 'Variance': variances, 'Mean': means})\n",
    "        sns.lineplot(data=df_variance, x='Time Point', y='Variance', marker='o', ax=ax_stats)\n",
    "        ax_stats.set_title(f'Variance of all PC for {cell_type}', fontsize=14)\n",
    "        ax_stats.set_xlabel('Time', fontsize=12)\n",
    "        ax_stats.set_ylabel(f'all PC Variance', fontsize=12)\n",
    "\n",
    "        sns.lineplot(data=df_variance, x='Time Point', y='Mean', marker='o', ax=ax_mean)\n",
    "        ax_mean.set_title(f'Mean of all PC for {cell_type}', fontsize=14)\n",
    "        ax_mean.set_xlabel('Time', fontsize=12)\n",
    "        ax_mean.set_ylabel(f'all PC Mean', fontsize=12)\n",
    "\n",
    "    for idx in range(n_cell_types, axes.shape[0]):\n",
    "        axes[idx, 0].axis('off')\n",
    "        axes[idx, 1].axis('off')\n",
    "        axes[idx, 2].axis('off')\n",
    "\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    plot_filename = os.path.join(save_dir, f\"{title.replace(' ', '_')}_all_PCs_{dataset_name}_density_stats.png\")\n",
    "    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
    "    plt.show()    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pcs_density_and_stats(result_dict, n_components, title = 'Density Plots of PC1 Across Cell Types')\n",
    "\n",
    "plot_pcs_density_and_stats(derivative_dict, n_components, title = 'Derivative Plots of PC1 Across Cell Types')\n",
    "\n",
    "plot_pcs_density_and_stats(derivative_square_dict, n_components, title = 'Diffusion Constant Plots of PC1 Across Cell Types')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_all_pcs_density_and_stats(derivative_dict, title = 'Derivative Plots of ALL PCs Across Cell Types')\n",
    "\n",
    "plot_all_pcs_density_and_stats(derivative_square_dict, title = 'Diffusion Constant Plots of ALL PCs Across Cell Types')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capedenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
